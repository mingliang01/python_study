1 先用Packet Capture在手机上抓包，初步确认一下
2 用charless抓包，可以修改，重复请求，确定一个必要的发送头
3 生成请求代码,postman可以直接生成，charles可以生成curl请求再转python

单车爬虫
1 地图上找到坐标，生成一个矩形，移动未知反复爬
2 多线程爬取
3 使用代理池
4 http代替https，如果能用则，速度更快，代理能用的也更多
5 多边型抓取，取多边形的最大矩形范围，再用shapely库过滤掉不包含的点
6 设置权重，权重高的位置偏移量小，还可以排除部分区域
7 坐标要在地图上显示，得转换，WGS84，GCJ-02，BD-09,然后用百度地图，高德地图的开发API直接显示
8 数据存csv文件,数据量大就压缩
9 想方便查询就存数据库，一天一张表
10 数据库用的PostgreSQL

共享汽车爬虫
1 相对固定的信息可以一天爬一次
2 签名，可以定时刷新APP，用mitmproxy写脚本抓签名参数，放入签名池，再用签名进行抓取
3 有的APP，用Packet Capture能抓包，charless抓不到包，可能是强制禁用了代理，但是能用VPN，可以用postern模拟一个VPN，先访问VPN，再转代理
4 SSL pinningg问题，会检测客户端证书是否和服务端证书匹配。比较难搞。需要对手机root，使用frida结合脚本来搞。
5 请求参数会变，只有想办法用appium模拟点击，或者伪造数据，中途用mitmproxy改数据等。

freelancer网站爬接单数据
1 html页面解析不易，容易失效，最好还是找到某个ajax请求返回的json来抓
2 遍历ID发请求抓数据，需要确定ID的边界
3 调用API次数有限制，需要计算爬取速度，多久能爬完，必要时用大量代理来突破调用次数限制。
4 考虑缩小调用范围，减少爬取次数
5 还要计算数据存储占用空间
6 已经抓过的ID要去重，放redis，可以实现断点续爬功能
7 数据压缩节省空间
8 JSON数据要存数据库用NoSQL,还有ElasticSearch搜索快
9 ElasticSearch自动识别的数据类型不准，可以先不用mapping导入一定量的数据，然后将ElasticSearch生成的映射到出来，修改字段后重新导入
10 用kibana做基础分析，生成一本在线小书
11 reveal.js结合百度echarts，可以做出动态的可以交互的页面
12 ujson比python自带的性能更好

爬某快递
1 先用charles抓包，发现有ts、sign这样的时间签名
2 获取wxapkg包，需要一个root后的手机，找包前先清理干净用过的小程序
3 反编译wxapkg,格式化JS文件
4 用VS code装JS插件进行代码分析
5 通过位置遍历爬取，但是边界不好确定，可以通过地图供应商提供的行政区域接口得到边界信息，百度JavaScript API(获取边界)，simplify(简化多边形)
6 dict-to-csv，json转CSV

文件存储数据的优势
1 抑郁数据迁移
2 易于清理空间
3 易于数据恢复
4 易于查看，跨平台不会出问题
5 数据库有依赖，还要额外维护
6 数据量过大时，插入数据库性能降低
