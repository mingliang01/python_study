1 先用Packet Capture在手机上抓包，初步确认一下
2 用charless抓包，可以修改，重复请求，确定一个必要的发送头
3 生成请求代码,postman可以直接生成，charles可以生成curl请求再转python

单车爬虫
1 地图上找到坐标，生成一个矩形，移动未知反复爬
2 多线程爬取
3 使用代理池
4 http代替https，如果能用则，速度更快，代理能用的也更多
5 多边型抓取，取多边形的最大矩形范围，再用shapely库过滤掉不包含的点
6 设置权重，权重高的位置偏移量小，还可以排除部分区域
7 坐标要在地图上显示，得转换，WGS84，GCJ-02，BD-09,然后用百度地图，高德地图的开发API直接显示
8 数据存csv文件,数据量大就压缩
9 想方便查询就存数据库，一天一张表

共享汽车爬虫
1 相对固定的信息可以一天爬一次
2 签名，可以定时刷新APP，用mitmproxy写脚本抓签名参数，放入签名池，再用签名进行抓取
3 有的APP，用Packet Capture能抓包，charless抓不到包，可能是强制禁用了代理，但是能用VPN，可以用postern模拟一个VPN，先访问VPN，再转代理
4 SSL pinningg问题，会检测客户端证书是否和服务端证书匹配。比较难搞。需要对手机root，使用frida结合脚本来搞。
5 请求参数会变，只有想办法用appium模拟点击，或者伪造数据，中途用mitmproxy改数据等。

freelancer网站爬接单数据
1 html页面解析不易，容易失效，最好还是找到某个ajax请求返回的json来抓
2 遍历ID发请求抓数据，需要确定ID的边界
3 调用API次数有限制，需要计算爬取速度，多久能爬完，必要时用大量代理来突破调用次数限制。
4 考虑缩小调用范围，减少爬取次数
5 还要计算数据存储占用空间
6 已经抓过的ID要去重，放redis，可以实现断点续爬功能
7 数据压缩节省空间